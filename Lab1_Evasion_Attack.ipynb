{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”´ Lab 1 â€” Evasion Attack\n",
    "### Certified AI Penetration Tester â€“ Red Team (CAIPT-RT)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ The Story\n",
    "\n",
    "Imagine you are a spammer. You want to send promotional messages to thousands of people, but there is a spam filter standing in your way â€” a machine learning model that has been trained to detect spam and block it before it reaches anyone's inbox.\n",
    "\n",
    "Your goal as an attacker is not to break the filter or hack into it. Instead, you want to **craft your spam message so cleverly that the filter does not recognize it as spam**, even though any human reading it clearly would.\n",
    "\n",
    "This is called an **Evasion Attack**. You are evading detection by manipulating your input.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“– What is an Evasion Attack?\n",
    "\n",
    "An evasion attack happens **after** a model has already been trained and deployed. The attacker does not touch the model or its training data. Instead, the attacker carefully modifies an input â€” just enough to fool the model â€” while keeping the input meaningful to a human.\n",
    "\n",
    "**Real world examples:**\n",
    "- Tweaking spam emails to bypass spam filters\n",
    "- Modifying malware signatures slightly to bypass AI-based antivirus software\n",
    "- Altering network traffic patterns to evade AI intrusion detection systems\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ—‚ï¸ What We Will Do in This Lab\n",
    "\n",
    "1. Load a real SMS spam dataset and explore it\n",
    "2. Convert the text messages into numbers the model can understand\n",
    "3. Train a spam classifier â€” this is the model we will attack\n",
    "4. Test the classifier on clean messages to confirm it works\n",
    "5. Use ART to perform an evasion attack\n",
    "6. Observe and reflect on the results\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ Step 1: Import the Tools We Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "# We import all the tools we need at the top of the notebook.\n",
    "# Think of this like gathering all your equipment before starting an experiment.\n",
    "#\n",
    "# numpy        : handles numbers and arrays (lists of numbers)\n",
    "# pandas       : loads and explores datasets, like a programmable spreadsheet\n",
    "# sklearn      : builds and trains machine learning models\n",
    "# art          : the Adversarial Robustness Toolbox - our attack toolkit\n",
    "# matplotlib   : draws charts and graphs\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# From scikit-learn we need:\n",
    "# TfidfVectorizer  : converts text messages into numbers\n",
    "# LogisticRegression: the type of model we will train as our spam filter\n",
    "# train_test_split : splits our data into training and testing portions\n",
    "# accuracy_score   : measures how accurate our model is\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# From ART we import the classifier wrapper and the evasion attack\n",
    "# SklearnClassifier : wraps our sklearn model so ART can attack it\n",
    "# HopSkipJump      : a powerful black-box evasion attack\n",
    "from art.estimators.classification import SklearnClassifier\n",
    "from art.attacks.evasion import HopSkipJump\n",
    "\n",
    "# Set a random seed so results are reproducible\n",
    "# This means everyone in the class gets the same numbers\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All tools imported successfully. Ready to begin.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“‚ Step 2: Load and Explore the Dataset\n",
    "\n",
    "We are using the **SMS Spam Collection dataset** â€” a real dataset containing 5,574 SMS messages, each labeled as either `spam` or `ham` (ham means legitimate, not spam).\n",
    "\n",
    "This dataset was collected for research into spam filtering and contains real spam messages that were collected from spam-reporting websites, and real legitimate messages collected from research volunteers.\n",
    "\n",
    "Before we do anything else, we need to **look at our data**. A good attacker â€” and a good defender â€” always understands the data they are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD THE DATASET\n",
    "# =============================================================================\n",
    "# The SMSSpamCollection file is a tab-separated text file.\n",
    "# Tab-separated means each line has two pieces of information separated by\n",
    "# a tab character: the label (spam or ham) and the message text.\n",
    "#\n",
    "# We tell pandas:\n",
    "#   sep='\\t'         : the file uses tabs to separate columns\n",
    "#   header=None      : the file has no header row\n",
    "#   names=[...]      : we give the columns our own names\n",
    "#   encoding='latin-1': handles special characters in some messages\n",
    "# =============================================================================\n",
    "\n",
    "df = pd.read_csv(\n",
    "    '../datasets/SMSSpamCollection',\n",
    "    sep='\\t',\n",
    "    header=None,\n",
    "    names=['label', 'message'],\n",
    "    encoding='latin-1'\n",
    ")\n",
    "\n",
    "print(f\"Dataset loaded successfully.\")\n",
    "print(f\"Total messages in dataset: {len(df)}\")\n",
    "print(\"\")\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(\"-\" * 60)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘€ What Do You See?\n",
    "\n",
    "Look at the first 5 rows printed above.\n",
    "\n",
    "- What are the two columns in this dataset?\n",
    "- Can you tell just by reading the messages which ones are spam and which are legitimate?\n",
    "- What patterns do you notice in the spam messages?\n",
    "\n",
    "Write your observations in your output folder before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPLORE THE DATASET\n",
    "# =============================================================================\n",
    "# Before training any model, we need to understand what we are working with.\n",
    "# How many spam vs legitimate messages are there?\n",
    "# This matters because if 95% of messages are legitimate, a model that just\n",
    "# guesses \"legitimate\" every time would be 95% accurate â€” but completely\n",
    "# useless as a spam filter. This is called class imbalance.\n",
    "# =============================================================================\n",
    "\n",
    "# Count how many messages belong to each label\n",
    "label_counts = df['label'].value_counts()\n",
    "\n",
    "print(\"Message counts by label:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Legitimate (ham) : {label_counts['ham']}\")\n",
    "print(f\"Spam             : {label_counts['spam']}\")\n",
    "print(f\"Total            : {len(df)}\")\n",
    "print(\"\")\n",
    "print(f\"Spam percentage  : {label_counts['spam']/len(df)*100:.1f}%\")\n",
    "print(f\"Ham percentage   : {label_counts['ham']/len(df)*100:.1f}%\")\n",
    "\n",
    "# Draw a bar chart to visualize the split\n",
    "plt.figure(figsize=(6, 4))\n",
    "label_counts.plot(kind='bar', color=['steelblue', 'tomato'])\n",
    "plt.title('Distribution of Spam vs Legitimate Messages')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Number of Messages')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/lab1_dataset_distribution.png')\n",
    "plt.show()\n",
    "print(\"Chart saved to outputs folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘€ What Do You See?\n",
    "\n",
    "Look at the numbers and the chart above.\n",
    "\n",
    "- What percentage of messages in this dataset are spam?\n",
    "- If a spam filter just labeled every single message as \"legitimate\" without reading them, what accuracy score would it get? Is that a good spam filter?\n",
    "- Why does the balance between spam and legitimate messages matter when training a model?\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¢ Step 3: Convert Text to Numbers\n",
    "\n",
    "Machine learning models cannot read text. They only understand numbers. So we need to convert each SMS message into a list of numbers that captures the meaning and content of the message.\n",
    "\n",
    "We will use a technique called **TF-IDF (Term Frequency - Inverse Document Frequency)**. This sounds complex but the idea is simple:\n",
    "\n",
    "- Words that appear frequently in spam messages (like \"FREE\", \"WIN\", \"PRIZE\") get high scores when they appear in a message\n",
    "- Words that appear in almost every message (like \"the\", \"a\", \"is\") get low scores because they are not useful for identifying spam\n",
    "\n",
    "The result is that each message becomes a long list of numbers â€” one number per possible word â€” representing how \"spammy\" the word usage in that message is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONVERT TEXT TO NUMBERS USING TF-IDF\n",
    "# =============================================================================\n",
    "# TfidfVectorizer does the following:\n",
    "#   1. Reads all messages and builds a vocabulary of every word it sees\n",
    "#   2. Converts each message into a vector (list) of numbers\n",
    "#      where each number represents the importance of one word\n",
    "#\n",
    "# max_features=5000 means we only keep the 5000 most useful words\n",
    "# (keeping all words would make the data very large and slow to process)\n",
    "# =============================================================================\n",
    "\n",
    "# Convert labels from text (spam/ham) to numbers (1/0)\n",
    "# The model needs numbers, not words, for the labels too\n",
    "# spam = 1, ham = 0\n",
    "df['label_num'] = df['label'].map({'spam': 1, 'ham': 0})\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# Fit the vectorizer on all messages and transform them into numbers\n",
    "# fit_transform does two things:\n",
    "#   fit      : learns the vocabulary from all messages\n",
    "#   transform: converts each message into a numerical vector\n",
    "X = vectorizer.fit_transform(df['message']).toarray()\n",
    "y = df['label_num'].values\n",
    "\n",
    "print(f\"Each message is now represented as a vector of {X.shape[1]} numbers.\")\n",
    "print(f\"Total messages converted: {X.shape[0]}\")\n",
    "print(\"\")\n",
    "\n",
    "# Show an example: what does the first message look like as numbers?\n",
    "print(\"Example: First message in the dataset\")\n",
    "print(f\"Original text : {df['message'][0]}\")\n",
    "print(f\"Label         : {df['label'][0]}\")\n",
    "print(f\"As numbers    : [{X[0][X[0]>0][:5]}...] (showing first 5 non-zero values)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘€ What Do You See?\n",
    "\n",
    "- Each message has been converted into a vector of 5000 numbers. What do most of those numbers likely equal, given that no single message uses all 5000 words?\n",
    "- Why do we need to convert text to numbers at all? Why can't the model just read the words directly?\n",
    "\n",
    "---\n",
    "\n",
    "## âœ‚ï¸ Step 4: Split the Data into Training and Testing Sets\n",
    "\n",
    "Before we train the model, we need to split our data into two separate groups:\n",
    "\n",
    "**Training set** â€” the examples the model will learn from. Think of this as the study material.\n",
    "\n",
    "**Testing set** â€” examples the model has never seen, used to check if it actually learned correctly. Think of this as the exam.\n",
    "\n",
    "This split is critical. If we tested the model on the same data it trained on, it would get high scores just by memorizing â€” like a student who gets the exact same questions on the exam that appeared in their homework. That would not tell us whether the model can handle new, unseen messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SPLIT DATA INTO TRAINING AND TESTING SETS\n",
    "# =============================================================================\n",
    "# train_test_split divides our data randomly.\n",
    "#\n",
    "# test_size=0.2 means:\n",
    "#   80% of messages go to the training set (model learns from these)\n",
    "#   20% of messages go to the testing set  (we test the model on these)\n",
    "#\n",
    "# stratify=y means the split keeps the same spam/ham ratio in both sets\n",
    "# so we do not accidentally put all spam in one set\n",
    "#\n",
    "# random_state=42 ensures everyone gets the same split (reproducible)\n",
    "# =============================================================================\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Data split complete.\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Training set size : {len(X_train)} messages\")\n",
    "print(f\"Testing set size  : {len(X_test)} messages\")\n",
    "print(\"\")\n",
    "print(f\"Training spam count : {sum(y_train == 1)}\")\n",
    "print(f"Training ham count  : {sum(y_train == 0)}\")\n",
    "print(\"\")\n",
    "print(f\"Testing spam count  : {sum(y_test == 1)}\")\n",
    "print(f\"Testing ham count   : {sum(y_test == 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘€ What Do You See?\n",
    "\n",
    "- How many messages are in the training set vs the testing set?\n",
    "- Is the spam-to-ham ratio roughly similar in both sets? Why does that matter?\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ‹ï¸ Step 5: Train the Spam Filter Model\n",
    "\n",
    "Now we train our spam filter. We are using a **Logistic Regression** model â€” one of the most reliable and interpretable models for text classification.\n",
    "\n",
    "Think of training like this: the model looks at thousands of messages it already knows the labels for, and it learns patterns. It figures out that messages containing words like \"FREE\", \"WINNER\", \"PRIZE\", \"URGENT\" tend to be spam, while messages containing words like \"home\", \"later\", \"dinner\" tend to be legitimate.\n",
    "\n",
    "During training you will see the model being fitted to the data. This happens very fast for a model this size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRAIN THE SPAM FILTER (LOGISTIC REGRESSION)\n",
    "# =============================================================================\n",
    "# LogisticRegression is a classification algorithm that learns a mathematical\n",
    "# boundary between two classes (spam vs ham).\n",
    "#\n",
    "# max_iter=1000 gives the model enough iterations to fully converge\n",
    "# (converge means it has finished learning and the results stabilized)\n",
    "#\n",
    "# The fit() function is where actual training happens.\n",
    "# We pass it:\n",
    "#   X_train : the message vectors (input)\n",
    "#   y_train : the correct labels  (what we want the model to learn)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Training the spam filter model...\")\n",
    "print(\"(This should take just a few seconds)\")\n",
    "print(\"\")\n",
    "\n",
    "# Create the model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Training complete!\")\n",
    "print(\"\")\n",
    "\n",
    "# Now test the model on the testing set it has never seen before\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Model accuracy on test set: {accuracy * 100:.2f}%\")\n",
    "print(\"\")\n",
    "print(\"Detailed performance breakdown:\")\n",
    "print(\"-\" * 50)\n",
    "print(classification_report(y_test, y_pred, target_names=['Ham (legitimate)', 'Spam']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘€ What Do You See?\n",
    "\n",
    "Look at the accuracy score and the detailed breakdown above.\n",
    "\n",
    "- What accuracy did the model achieve? Is that high enough to trust as a spam filter?\n",
    "- Look at the \"precision\" and \"recall\" numbers for spam. Precision means \"of all the messages it called spam, how many actually were?\" Recall means \"of all the actual spam, how many did it catch?\"\n",
    "- Which is more dangerous â€” a model with low precision (too many false alarms) or low recall (missing real spam)? Why?\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Step 6: Test the Model Manually\n",
    "\n",
    "Before we attack the model, let us confirm it works by testing it on a few messages we write ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MANUALLY TEST THE SPAM FILTER\n",
    "# =============================================================================\n",
    "# We write a few test messages and see how the model classifies them.\n",
    "# This confirms the model is working before we try to fool it.\n",
    "# =============================================================================\n",
    "\n",
    "def classify_message(message):\n",
    "    \"\"\"\n",
    "    Takes a text message, converts it to numbers using our vectorizer,\n",
    "    and returns the model's prediction with confidence score.\n",
    "    \"\"\"\n",
    "    # Convert the message to numbers using the same vectorizer we trained\n",
    "    message_vector = vectorizer.transform([message]).toarray()\n",
    "    \n",
    "    # Get the model's prediction (0=ham, 1=spam)\n",
    "    prediction = model.predict(message_vector)[0]\n",
    "    \n",
    "    # Get the confidence score (probability of being spam)\n",
    "    confidence = model.predict_proba(message_vector)[0][1]\n",
    "    \n",
    "    label = \"SPAM\" if prediction == 1 else \"HAM (legitimate)\"\n",
    "    return label, confidence\n",
    "\n",
    "# Test messages - a mix of obvious spam and legitimate messages\n",
    "test_messages = [\n",
    "    \"Congratulations! You have WON a FREE iPhone! Click here to claim your PRIZE now!\",\n",
    "    \"Hey, are you coming to dinner tonight? Let me know!\",\n",
    "    \"URGENT: Your account has been suspended. Call us immediately to verify your details.\",\n",
    "    \"Can you pick up some milk on your way home?\",\n",
    "    \"FREE entry into our weekly competition to win FA Cup Final tickets!\"\n",
    "]\n",
    "\n",
    "print(\"Manual spam filter test:\")\n",
    "print(\"=\" * 70)\n",
    "for msg in test_messages:\n",
    "    label, confidence = classify_message(msg)\n",
    "    print(f\"Message  : {msg[:60]}...\" if len(msg) > 60 else f\"Message  : {msg}\")\n",
    "    print(f\"Decision : {label} (spam confidence: {confidence:.2%})\")\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘€ What Do You See?\n",
    "\n",
    "- Did the model correctly identify the spam messages? And the legitimate ones?\n",
    "- Look at the confidence scores. High confidence means the model is very sure. Low confidence means it is uncertain. Which messages was the model most confident about?\n",
    "\n",
    "### ðŸ§ª Try This\n",
    "\n",
    "In the cell below, write your own test message and run it through the classifier. Try:\n",
    "1. An obvious spam message\n",
    "2. A borderline message that could go either way\n",
    "3. A message that looks like spam but is actually legitimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TRY IT YOURSELF\n",
    "# =============================================================================\n",
    "# Change the message below to whatever you want to test.\n",
    "# Run this cell and observe how confident the model is.\n",
    "# =============================================================================\n",
    "\n",
    "# ðŸ‘‡ CHANGE THIS MESSAGE TO ANYTHING YOU WANT TO TEST\n",
    "my_message = \"Type your own message here and see what happens!\"\n",
    "\n",
    "label, confidence = classify_message(my_message)\n",
    "print(f\"Your message : {my_message}\")\n",
    "print(f\"Decision     : {label}\")\n",
    "print(f\"Confidence   : {confidence:.2%} chance of being spam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ”´ Step 7: Perform the Evasion Attack\n",
    "\n",
    "Now the real attack begins.\n",
    "\n",
    "We will use ART's **HopSkipJump** attack. This is a black-box evasion attack, meaning the attacker does not need to know anything about the model's internal structure â€” they only need to be able to send inputs and get predictions back. This is very realistic because in the real world, attackers usually cannot see inside the model they are attacking.\n",
    "\n",
    "**What HopSkipJump does:** It takes a spam message that the model correctly identifies as spam, and it makes tiny mathematical adjustments to the numerical representation of that message, repeatedly testing whether the model still calls it spam. It keeps adjusting until it finds a version that the model classifies as legitimate â€” while keeping the changes as small as possible.\n",
    "\n",
    "**Important note:** Because we are working in numerical space (the TF-IDF vectors), the \"adversarial example\" we generate is a modified numerical vector. We will show you how to interpret this back in terms of what changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# WRAP THE MODEL IN ART'S CLASSIFIER\n",
    "# =============================================================================\n",
    "# ART needs our model wrapped in its own SklearnClassifier format.\n",
    "# This wrapper gives ART access to the model's predictions so it can\n",
    "# run its attacks. Think of it as putting our model inside ART's testing rig.\n",
    "#\n",
    "# clip_values=(0,1) tells ART that our feature values range from 0 to 1\n",
    "# (TF-IDF scores are always between 0 and 1)\n",
    "# =============================================================================\n",
    "\n",
    "art_classifier = SklearnClassifier(model=model, clip_values=(0, 1))\n",
    "\n",
    "print(\"Model wrapped in ART classifier. Ready to attack.\")\n",
    "print(\"\")\n",
    "\n",
    "# Select a small sample of spam messages from the test set to attack\n",
    "# We pick messages the model currently classifies CORRECTLY as spam\n",
    "# (there is no point attacking messages the model already gets wrong)\n",
    "spam_indices = np.where((y_test == 1) & (model.predict(X_test) == 1))[0]\n",
    "\n",
    "# Take the first 5 correctly-identified spam messages\n",
    "attack_sample = X_test[spam_indices[:5]]\n",
    "attack_labels = y_test[spam_indices[:5]]\n",
    "\n",
    "print(f\"Selected {len(attack_sample)} spam messages to attack.\")\n",
    "print(f\"Model currently classifies all of these correctly as SPAM.\")\n",
    "print(\"\")\n",
    "print(\"Now launching the evasion attack...\")\n",
    "print(\"(This may take 1-2 minutes as the attack iterates)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RUN THE HOPSKIPJUMP EVASION ATTACK\n",
    "# =============================================================================\n",
    "# HopSkipJump attack parameters explained:\n",
    "#\n",
    "# targeted=False    : we are doing an untargeted attack\n",
    "#                     (we just want to fool the model, not make it predict\n",
    "#                     a specific wrong class)\n",
    "#\n",
    "# max_iter=20       : the attack will try up to 20 rounds of adjustments\n",
    "#                     More iterations = stronger attack but slower\n",
    "#\n",
    "# max_eval=100      : maximum number of model queries per iteration\n",
    "#\n",
    "# init_eval=10      : number of initial evaluations to start the attack\n",
    "# =============================================================================\n",
    "\n",
    "attack = HopSkipJump(\n",
    "    classifier=art_classifier,\n",
    "    targeted=False,\n",
    "    max_iter=20,\n",
    "    max_eval=100,\n",
    "    init_eval=10\n",
    ")\n",
    "\n",
    "# Generate adversarial examples\n",
    "# This is where the attack actually runs\n",
    "# x_adv contains the modified versions of our spam messages\n",
    "x_adv = attack.generate(x=attack_sample)\n",
    "\n",
    "print(\"Attack complete!\")\n",
    "print(\"\")\n",
    "\n",
    "# Now check: how does the model classify the adversarial examples?\n",
    "original_predictions = model.predict(attack_sample)\n",
    "adversarial_predictions = model.predict(x_adv)\n",
    "\n",
    "print(\"Results:\")\n",
    "print(\"=\" * 50)\n",
    "for i in range(len(attack_sample)):\n",
    "    orig = \"SPAM\" if original_predictions[i] == 1 else \"HAM\"\n",
    "    adv  = \"SPAM\" if adversarial_predictions[i] == 1 else \"HAM\"\n",
    "    fooled = \"âœ“ FOOLED\" if adversarial_predictions[i] == 0 else \"âœ— Still detected\"\n",
    "    print(f\"Message {i+1}: Original={orig} | After attack={adv} | {fooled}\")\n",
    "\n",
    "print(\"\")\n",
    "success_rate = np.mean(adversarial_predictions == 0) * 100\n",
    "print(f\"Attack success rate: {success_rate:.0f}% of spam messages evaded detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ‘€ What Do You See?\n",
    "\n",
    "Look at the results table carefully.\n",
    "\n",
    "- How many of the spam messages successfully evaded the filter after the attack?\n",
    "- The attack modified the numerical representation of the message. The filter now thinks those messages are legitimate. What does this tell you about how spam filters can be fooled?\n",
    "- In a real-world scenario, what would an attacker do with this capability?\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š Step 8: Measure the Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MEASURE THE PERTURBATION (HOW MUCH DID THE ATTACK CHANGE THE MESSAGES?)\n",
    "# =============================================================================\n",
    "# A good evasion attack makes as few changes as possible.\n",
    "# We measure the \"distance\" between the original and adversarial examples\n",
    "# using L2 norm - a mathematical measure of how different two vectors are.\n",
    "# Smaller distance = more subtle attack.\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Measuring how much the attack changed each message:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i in range(len(attack_sample)):\n",
    "    # Calculate the L2 distance between original and adversarial\n",
    "    perturbation = np.linalg.norm(x_adv[i] - attack_sample[i])\n",
    "    fooled = adversarial_predictions[i] == 0\n",
    "    print(f\"Message {i+1}: Change magnitude = {perturbation:.4f} | Evaded = {fooled}\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Note: A smaller change magnitude means the attack was more subtle.\")\n",
    "print(\"In a real-world text attack, this would mean fewer word changes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§ª Try This â€” Change the Attack Strength\n",
    "\n",
    "Go back to the attack cell above and change `max_iter=20` to `max_iter=5`, then rerun the attack cells. \n",
    "\n",
    "- Does a weaker attack (fewer iterations) still successfully evade the filter?\n",
    "- How does the change magnitude differ?\n",
    "\n",
    "Then try `max_iter=50` for a stronger attack.\n",
    "\n",
    "- Does more iterations always mean a more successful attack?\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ’­ Step 9: Reflect\n",
    "\n",
    "Answer the following questions in your own words and save them to your outputs folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# REFLECTION - SAVE YOUR ANSWERS\n",
    "# =============================================================================\n",
    "# Edit the answers below and run this cell to save them to your outputs folder.\n",
    "# =============================================================================\n",
    "\n",
    "reflection = \"\"\"\n",
    "LAB 1 - EVASION ATTACK REFLECTION\n",
    "===================================\n",
    "\n",
    "Q1: In plain English, what is an evasion attack?\n",
    "A1: [TYPE YOUR ANSWER HERE]\n",
    "\n",
    "Q2: The attack modified the numerical representation of spam messages.\n",
    "    In a real text-based attack, what kinds of changes might an attacker\n",
    "    make to a spam email to evade a filter? (Think: word substitutions,\n",
    "    misspellings, extra characters...)\n",
    "A2: [TYPE YOUR ANSWER HERE]\n",
    "\n",
    "Q3: What is one defensive measure that could reduce the effectiveness\n",
    "    of evasion attacks against a spam filter?\n",
    "A3: [TYPE YOUR ANSWER HERE]\n",
    "\n",
    "Q4: Name one real-world system other than a spam filter where an\n",
    "    evasion attack could cause serious harm.\n",
    "A4: [TYPE YOUR ANSWER HERE]\n",
    "\"\"\"\n",
    "\n",
    "# Save the reflection to the outputs folder\n",
    "with open('../outputs/Lab1_Reflection.txt', 'w') as f:\n",
    "    f.write(reflection)\n",
    "\n",
    "print(\"Reflection template saved to outputs/Lab1_Reflection.txt\")\n",
    "print(\"Open that file, fill in your answers, and save it.\")\n",
    "print(\"\")\n",
    "print(reflection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… Lab 1 Complete\n",
    "\n",
    "You have successfully:\n",
    "- Loaded and explored a real SMS spam dataset\n",
    "- Trained a spam filter classifier\n",
    "- Performed an evasion attack using ART's HopSkipJump\n",
    "- Measured the attack's success rate and subtlety\n",
    "\n",
    "When you are ready, return to [START_HERE.ipynb](START_HERE.ipynb) and open Lab 2 â€” Poisoning Attack.\n",
    "\n",
    "---\n",
    "*Lab built with the Adversarial Robustness Toolbox (ART)*  \n",
    "*https://github.com/Trusted-AI/adversarial-robustness-toolbox*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
