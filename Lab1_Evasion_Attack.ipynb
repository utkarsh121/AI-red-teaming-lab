{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ðŸ”´ Lab 1 â€” Evasion Attack\n### Certified AI Penetration Tester â€“ Red Team (CAIPT-RT)\n\n---\n\n## ðŸŽ¯ The Story\n\nImagine you are a spammer. You want to send promotional messages to thousands of people, but there is a spam filter standing in your way â€” a machine learning model trained to detect spam and block it before it reaches anyone's inbox.\n\nYour goal as an attacker is not to break the filter or hack into it. Instead, you want to **craft your spam message so cleverly that the filter does not recognise it as spam**, even though any human reading it clearly would.\n\nThis is called an **Evasion Attack**. You are evading detection by manipulating your input.\n\n---\n\n## ðŸ“– What is an Evasion Attack?\n\nAn evasion attack happens **after** a model has already been trained and deployed. The attacker does not touch the model or its training data. Instead, the attacker carefully modifies an input just enough to fool the model while keeping it meaningful to a human.\n\n**Real world examples:**\n- Tweaking spam emails to bypass spam filters\n- Modifying malware signatures slightly to bypass AI-based antivirus software\n- Altering network traffic patterns to evade AI intrusion detection systems\n\n---\n\n## ðŸ—‚ï¸ What We Will Do in This Lab\n\n1. Load a real SMS spam dataset and explore it\n2. Convert text messages into numbers the model can understand\n3. Train a spam classifier â€” this is the model we will attack\n4. Confirm the classifier works before attacking it\n5. Use ART to perform an evasion attack\n6. Measure and reflect on the results\n\n---\n\n## âš™ï¸ Step 1: Import the Tools We Need"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# IMPORTS\n# =============================================================================\n# numpy      : handles numbers and arrays\n# pandas     : loads and explores datasets\n# sklearn    : builds and trains machine learning models\n# art        : the Adversarial Robustness Toolbox - our attack toolkit\n# matplotlib : draws charts and graphs\n#\n# We suppress the PyTorch warning from ART since we are not using PyTorch.\n# =============================================================================\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n\nfrom art.estimators.classification import SklearnClassifier\nfrom art.attacks.evasion import HopSkipJump\n\nnp.random.seed(42)\nprint(\"All tools imported successfully. Ready to begin.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## ðŸ“‚ Step 2: Load and Explore the Dataset\n\nWe are using the **SMS Spam Collection dataset** â€” 5,574 real SMS messages each labeled as either `spam` or `ham` (ham means legitimate).\n\nBefore training anything, we always explore the data first. A good attacker â€” and a good defender â€” understands the data they are working with."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# LOAD THE DATASET\n# =============================================================================\n# The SMSSpamCollection file is tab-separated â€” each line has two pieces\n# of information separated by a tab: the label (spam or ham) and the message.\n# =============================================================================\n\ndf = pd.read_csv(\n    '../datasets/SMSSpamCollection',\n    sep='\\t',\n    header=None,\n    names=['label', 'message'],\n    encoding='latin-1'\n)\n\nprint(f\"Dataset loaded successfully.\")\nprint(f\"Total messages: {len(df)}\")\nprint(\"\")\nprint(\"First 5 rows:\")\nprint(\"-\" * 60)\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ðŸ‘€ What Do You See?\n\nLook at the first 5 rows printed above.\n\n- What are the two columns in this dataset?\n- Can you tell just by reading the messages which ones are spam?\n- What patterns do you notice in the spam messages?\n\n---"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# EXPLORE THE DATASET\n# =============================================================================\n# How many spam vs legitimate messages are there?\n# This matters because a model that guesses \"legitimate\" every single time\n# would score well on accuracy but be completely useless as a spam filter.\n# =============================================================================\n\nlabel_counts = df['label'].value_counts()\n\nprint(\"Message counts by label:\")\nprint(\"-\" * 30)\nprint(f\"Legitimate (ham) : {label_counts['ham']}\")\nprint(f\"Spam             : {label_counts['spam']}\")\nprint(f\"Total            : {len(df)}\")\nprint(\"\")\nprint(f\"Spam percentage  : {label_counts['spam']/len(df)*100:.1f}%\")\nprint(f\"Ham percentage   : {label_counts['ham']/len(df)*100:.1f}%\")\n\nplt.figure(figsize=(6, 4))\nlabel_counts.plot(kind='bar', color=['steelblue', 'tomato'])\nplt.title('Distribution of Spam vs Legitimate Messages')\nplt.xlabel('Label')\nplt.ylabel('Number of Messages')\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.savefig('../outputs/lab1_dataset_distribution.png')\nplt.show()\nprint(\"Chart saved to outputs folder.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ðŸ‘€ What Do You See?\n\n- What percentage of messages are spam?\n- If a filter labeled every message as legitimate without reading it, what accuracy would it get? Is that a good spam filter?\n- Why does the balance between spam and legitimate messages matter when training a model?\n\n---\n\n## ðŸ”¢ Step 3: Convert Text to Numbers\n\nMachine learning models cannot read text â€” they only understand numbers. We use **TF-IDF (Term Frequency - Inverse Document Frequency)** to convert each message into a list of numbers.\n\nThe idea is simple: words that appear a lot in spam messages (like FREE, WIN, PRIZE) get high scores. Words that appear in almost every message (like the, a, is) get low scores because they are not useful for identifying spam."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CONVERT TEXT TO NUMBERS USING TF-IDF\n# =============================================================================\n# max_features=5000 means we keep the 5000 most useful words.\n# Each message becomes a vector of 5000 numbers.\n# =============================================================================\n\ndf['label_num'] = df['label'].map({'spam': 1, 'ham': 0})\n\nvectorizer = TfidfVectorizer(max_features=5000)\nX = vectorizer.fit_transform(df['message']).toarray()\ny = df['label_num'].values\n\nprint(f\"Each message is now a vector of {X.shape[1]} numbers.\")\nprint(f\"Total messages converted: {X.shape[0]}\")\nprint(\"\")\nprint(f\"Example - first message:\")\nprint(f\"  Original : {df['message'][0]}\")\nprint(f\"  Label    : {df['label'][0]}\")\nprint(f\"  Non-zero values in vector: {np.count_nonzero(X[0])} out of {X.shape[1]}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ðŸ‘€ What Do You See?\n\n- Each message has been converted into 5000 numbers. Why do most of those numbers equal zero?\n- Why can the model not just read the words directly?\n\n---\n\n## âœ‚ï¸ Step 4: Split Data into Training and Testing Sets\n\nWe split data into two groups:\n\n**Training set** â€” the examples the model learns from. Like study material.\n\n**Testing set** â€” examples the model has never seen, used to check if it actually learned. Like an exam.\n\nIf we tested on the same data used for training, the model would just memorise answers â€” like a student who gets the exact same questions on the exam as in their homework."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SPLIT INTO TRAINING AND TESTING SETS\n# =============================================================================\n# test_size=0.2  : 80% training, 20% testing\n# stratify=y     : keeps same spam/ham ratio in both sets\n# random_state=42: everyone gets the same split (reproducible)\n# =============================================================================\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nprint(\"Data split complete.\")\nprint(\"-\" * 40)\nprint(f\"Training set : {len(X_train)} messages\")\nprint(f\"Testing set  : {len(X_test)} messages\")\nprint(\"\")\nprint(f\"Training spam : {sum(y_train == 1)} | Training ham : {sum(y_train == 0)}\")\nprint(f\"Testing spam  : {sum(y_test == 1)}  | Testing ham  : {sum(y_test == 0)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ðŸ‘€ What Do You See?\n\n- Is the spam-to-ham ratio similar in both sets? Why does that matter?\n\n---\n\n## ðŸ‹ï¸ Step 5: Train the Spam Filter Model\n\nNow we train the spam filter. We use **Logistic Regression** â€” a reliable model for text classification.\n\nTraining means the model studies thousands of labeled messages and learns patterns. It figures out that messages with FREE, WINNER, URGENT tend to be spam, while messages with home, later, dinner tend to be legitimate."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TRAIN THE SPAM FILTER\n# =============================================================================\n# LogisticRegression learns a mathematical boundary between spam and ham.\n# fit() is where training actually happens.\n# We pass it X_train (message vectors) and y_train (correct labels).\n# =============================================================================\n\nprint(\"Training the spam filter...\")\nprint(\"\")\n\nmodel = LogisticRegression(max_iter=1000, random_state=42)\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\n\nprint(\"Training complete!\")\nprint(\"\")\nprint(f\"Accuracy on test set: {accuracy * 100:.2f}%\")\nprint(\"\")\nprint(\"Detailed breakdown:\")\nprint(\"-\" * 50)\nprint(classification_report(y_test, y_pred, target_names=['Ham (legitimate)', 'Spam']))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ðŸ‘€ What Do You See?\n\n- What accuracy did the model achieve? Is that high enough to trust?\n- Look at precision and recall for spam. Precision = of all messages it called spam, how many actually were? Recall = of all actual spam, how many did it catch?\n- Which is more dangerous â€” low precision (too many false alarms) or low recall (missing real spam)?\n\n---\n\n## ðŸŽ¯ Step 6: Test the Model Manually\n\nBefore attacking, confirm the model works by testing it on messages you write yourself."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# MANUALLY TEST THE SPAM FILTER\n# =============================================================================\n\ndef classify_message(message):\n    vec = vectorizer.transform([message]).toarray()\n    prediction = model.predict(vec)[0]\n    confidence = model.predict_proba(vec)[0][1]\n    label = \"SPAM\" if prediction == 1 else \"HAM (legitimate)\"\n    return label, confidence\n\ntest_messages = [\n    \"Congratulations! You have WON a FREE iPhone! Click here to claim your PRIZE now!\",\n    \"Hey, are you coming to dinner tonight? Let me know!\",\n    \"URGENT: Your account has been suspended. Call us immediately to verify your details.\",\n    \"Can you pick up some milk on your way home?\",\n    \"FREE entry into our weekly competition to win FA Cup Final tickets!\"\n]\n\nprint(\"Manual spam filter test:\")\nprint(\"=\" * 70)\nfor msg in test_messages:\n    label, confidence = classify_message(msg)\n    display = msg[:60] + \"...\" if len(msg) > 60 else msg\n    print(f\"Message  : {display}\")\n    print(f\"Decision : {label} (spam confidence: {confidence:.2%})\")\n    print(\"-\" * 70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ðŸ‘€ What Do You See?\n\n- Did the model correctly identify the spam and legitimate messages?\n- Which messages was the model most confident about?\n\n### ðŸ§ª Try This\n\nEdit the cell below and write your own test message. Try:\n1. An obvious spam message\n2. A borderline message that could go either way\n3. A message that looks like spam but is actually legitimate"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# TRY IT YOURSELF - change the message below and run this cell\n# =============================================================================\n\nmy_message = \"Type your own message here and see what happens!\"\n\nlabel, confidence = classify_message(my_message)\nprint(f\"Your message : {my_message}\")\nprint(f\"Decision     : {label}\")\nprint(f\"Confidence   : {confidence:.2%} chance of being spam\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## ðŸ”´ Step 7: Perform the Evasion Attack\n\nNow the real attack begins.\n\nWe use ART's **HopSkipJump** attack. This is a black-box evasion attack â€” the attacker only needs to send inputs and get predictions back. They never see inside the model. This is realistic because real attackers usually cannot see the model they are attacking.\n\n**What it does:** Takes spam messages the model correctly identifies, makes tiny mathematical adjustments to their numerical vectors, and keeps adjusting until the model classifies them as legitimate."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# WRAP THE MODEL IN ART AND SELECT SPAM SAMPLES TO ATTACK\n# =============================================================================\n\nart_classifier = SklearnClassifier(model=model, clip_values=(0, 1))\n\n# Select spam messages the model currently gets right\n# No point attacking messages the model already gets wrong\nspam_indices = np.where((y_test == 1) & (model.predict(X_test) == 1))[0]\nattack_sample = X_test[spam_indices[:5]]\n\nprint(f\"Selected {len(attack_sample)} correctly-identified spam messages to attack.\")\nprint(\"Model currently classifies ALL of these as SPAM.\")\nprint(\"\")\nprint(\"Launching evasion attack...\")\nprint(\"(This may take 1-2 minutes)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# RUN THE HOPSKIPJUMP EVASION ATTACK\n# =============================================================================\n# targeted=False : just fool the model, not force a specific prediction\n# max_iter=20    : up to 20 rounds of adjustments\n# max_eval=100   : maximum model queries per iteration\n# =============================================================================\n\nattack = HopSkipJump(\n    classifier=art_classifier,\n    targeted=False,\n    max_iter=20,\n    max_eval=100,\n    init_eval=10\n)\n\nx_adv = attack.generate(x=attack_sample)\n\nprint(\"Attack complete!\")\nprint(\"\")\n\noriginal_predictions = model.predict(attack_sample)\nadversarial_predictions = model.predict(x_adv)\n\nprint(\"Results:\")\nprint(\"=\" * 55)\nfor i in range(len(attack_sample)):\n    orig = \"SPAM\" if original_predictions[i] == 1 else \"HAM\"\n    adv  = \"SPAM\" if adversarial_predictions[i] == 1 else \"HAM\"\n    fooled = \"âœ“ FOOLED\" if adversarial_predictions[i] == 0 else \"âœ— Still detected\"\n    print(f\"Message {i+1}: Original={orig} | After attack={adv} | {fooled}\")\n\nprint(\"\")\nsuccess_rate = np.mean(adversarial_predictions == 0) * 100\nprint(f\"Attack success rate: {success_rate:.0f}% of spam messages evaded detection\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### ðŸ‘€ What Do You See?\n\n- How many spam messages successfully evaded the filter?\n- The attack modified numerical vectors. What does this tell you about how spam filters can be fooled?\n- In a real-world scenario, what would an attacker do with this capability?\n\n### ðŸ§ª Try This â€” Change the Attack Strength\n\nGo back to the attack cell and change `max_iter=20` to `max_iter=5`, then rerun.\n\n- Does a weaker attack still successfully evade the filter?\n- Then try `max_iter=50`. Does more always mean better?\n\n---\n\n## ðŸ’­ Step 8: Reflect"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# REFLECTION - edit your answers and run to save\n# =============================================================================\n\nreflection = \"\"\"\nLAB 1 - EVASION ATTACK REFLECTION\n===================================\n\nQ1: In plain English, what is an evasion attack?\nA1: [TYPE YOUR ANSWER HERE]\n\nQ2: In a real text-based attack, what kinds of changes might an attacker\n    make to a spam email to evade a filter?\nA2: [TYPE YOUR ANSWER HERE]\n\nQ3: What is one defensive measure that could reduce evasion attack effectiveness?\nA3: [TYPE YOUR ANSWER HERE]\n\nQ4: Name one real-world system other than spam where an evasion attack\n    could cause serious harm.\nA4: [TYPE YOUR ANSWER HERE]\n\"\"\"\n\nwith open('../outputs/Lab1_Reflection.txt', 'w') as f:\n    f.write(reflection)\n\nprint(\"Reflection saved to outputs/Lab1_Reflection.txt\")\nprint(reflection)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## âœ… Lab 1 Complete\n\nYou have successfully trained a spam filter and performed an evasion attack against it using ART.\n\nReturn to [START_HERE.ipynb](START_HERE.ipynb) and open Lab 2 â€” Poisoning Attack.\n\n---\n*Built with the Adversarial Robustness Toolbox (ART) â€” https://github.com/Trusted-AI/adversarial-robustness-toolbox*"
  }
 ]
}